---
layout: post
title: "How LLMs might help us scale world class healthcare to everyone?"
author: Tao Tu
homepage: "https://scholar.google.com/citations?user=VlR6u4AAAAAJ&hl=en"
image: "https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=VlR6u4AAAAAJ&citpid=2"
org: "Google Research"
time: 2024-04-10
hour: 12:15 - 13:00 ET
loc: "Rice 540"
zoom: "https://virginia.zoom.us/j/91940551411?pwd=WWFjVVdhaWNPMVRWQXBzcHRlcjJsUT09"
editor: Yen-Ling Kuo
---

**Abstract**
In recent years, the field of AI has been revolutionized by the emergence of Transformers and Large Language Models. However, perhaps nowhere is their impact likely to be more profound than in the biomedicine where they have the potential to act as care multipliers, help improve our understanding of biology and solve the burden of diseases. In this talk, I will introduce recent works from my team at Google AI, Med-PaLM, Med-PaLM 2, Med-PaLM M and AMIE which I believe are key milestones towards such a future.
 
Med-PaLM and Med-PaLM 2 were the first AI systems to obtain passing and expert level scores on US Medical License exam questions respectively, a long standing grand challenge in AI. Med-PaLM M was the first demonstration of a generalist, multimodal, biomedical AI system. More recently, two recent studies highlight AMIE's promising capabilities. In a double-blind, randomized study, AMIE performed competitively against Primary Care Physicians in text consultations. Additionally, a separate study demonstrated AMIE's significant assistive potential for clinicians facing complex diagnostic challenges.

I will outline the motivation, principles and technical innovations underpinning these systems. Finally, I will sketch out a vision for how we might be able to leverage such powerful systems to help scale world class healthcare to everyone and make medicine a humane endeavor again.

**Bio**
Tao Tu is a senior research engineer at Google Research. He is working at the intersection of large language models and biomedicine and the lead author of Med-PaLM, Med-PaLM Multimodal, and conversational dialogistic AI AMIE. He obtained his PhD from Columbia University in Biomedical Engineering. His research was focused on multimodal brain imaging. He worked on machine learning methods to combine information from simultaneously acquired EEG and fMRI in order to understand human cognition and behavior.

